{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_EV7ugtm7_9y"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset: Banco de Imagens"
      ]
    },
    {
      "metadata": {
        "id": "kVUPPvkD7_9z"
      },
      "cell_type": "markdown",
      "source": [
        "##Objetivo\n",
        "- ClassificaÃ§Ã£o de Imagens utilizando PyTorch e Yolov5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Autor\n",
        "\n",
        "#####Enio Kilder Oliveira da Silva            \n",
        "Turma: 2023.1"
      ],
      "metadata": {
        "id": "VSVe_xBtn5yH"
      }
    },
    {
      "metadata": {
        "id": "IaDYWmMy7_91"
      },
      "cell_type": "markdown",
      "source": [
        "## PreparaÃ§Ã£o"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando as Bibliotecas"
      ],
      "metadata": {
        "id": "WIqKZFbk_Vx0"
      }
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-05T21:13:42.975070Z",
          "start_time": "2017-10-05T21:13:41.562722Z"
        },
        "id": "xv5iGRiS7_92"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plot\n",
        "import os\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "#from huggingface_hub import push_to_hub_keras\n",
        "import scipy.stats as stats\n",
        "import sklearn\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuygbBLg9fOm",
        "outputId": "f7f6b09d-ce2c-431d-b60f-47a0e88644ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 27.1/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparando o ambiente"
      ],
      "metadata": {
        "id": "fZBllmPz_TgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YCjh46qKuqpCtCnbreiF\")\n",
        "project = rf.workspace(\"eniokilder\").project(\"banco-imagem\")\n",
        "dataset = project.version(1).download(\"folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i-7kXADD_DjM",
        "outputId": "f23c9e3b-b57c-4cfd-91d1-77652fc98421"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.7-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.16.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.43.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.3)\n",
            "Installing collected packages: python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.8.1.78\n",
            "    Uninstalling opencv-python-headless-4.8.1.78:\n",
            "      Successfully uninstalled opencv-python-headless-4.8.1.78\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.7.22\n",
            "    Uninstalling certifi-2023.7.22:\n",
            "      Successfully uninstalled certifi-2023.7.22\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.7 supervision-0.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cv2",
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Banco-Imagem-1 to folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16320/16320 [00:00<00:00, 33889.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Banco-Imagem-1 in folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 382/382 [00:00<00:00, 4349.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baixando os modelos treinados do ImageNet prÃ©-treinados no ImageNet usando YOLOv5 Utils"
      ],
      "metadata": {
        "id": "0t5qocKbfvUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../yolov5\n",
        "from utils.downloads import attempt_download\n",
        "#'n'=avioes, 's'=carros, 'm'=motos, 'l'=barcos, 'x'=helicopteros\n",
        "p5 = ['n', 's', 'm', 'l', 'x']  # P5 models\n",
        "cls = [f'{x}-cls' for x in p5]  # classification models\n",
        "\n",
        "for x in cls:\n",
        "    attempt_download(f'weights/yolov5{x}.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhMypmYAJ583",
        "outputId": "181fc340-422b-4485-901d-6cc92ceb681a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n-cls.pt to weights/yolov5n-cls.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.87M/4.87M [00:00<00:00, 36.1MB/s]\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s-cls.pt to weights/yolov5s-cls.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.5M/10.5M [00:00<00:00, 96.4MB/s]\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m-cls.pt to weights/yolov5m-cls.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24.9M/24.9M [00:00<00:00, 182MB/s]\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l-cls.pt to weights/yolov5l-cls.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50.9M/50.9M [00:00<00:00, 234MB/s]\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x-cls.pt to weights/yolov5x-cls.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92.0M/92.0M [00:00<00:00, 211MB/s]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "with open( \"/content/yolov5/models/yolov5n.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "metadata": {
        "id": "gEt0cDDKroKn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cat /content/yolov5/models/yolov5n.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE1JbtzWonD5",
        "outputId": "36815f20-81d7-4802-d009-2c95f1d8c239"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.25  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "id": "Y8uBAePbscE0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "metadata": {
        "id": "WoqOLBg8selX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dTKdvz3q7_97"
      },
      "cell_type": "markdown",
      "source": [
        "## Treinando e Validando os Dados Personalizados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = dataset.location.split(os.sep)[-1]\n",
        "os.environ[\"DATASET_NAME\"] = dataset_name"
      ],
      "metadata": {
        "id": "zM2pMDmHXeAp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinando sobre um modelo personalizado"
      ],
      "metadata": {
        "id": "MpUEVBW1W05E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'n'=avioes, 's'=carros, 'm'=motos, 'l'=barcos, 'x'=helicopteros\n",
        "%%time\n",
        "%cd ../yolov5\n",
        "!python classify/train.py --model yolov5n-cls.pt --data $DATASET_NAME --epochs 128 --batch 16 --img 320 --pretrained weights/yolov5n-cls.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qsZokEzX_1A",
        "outputId": "13872948-9866-4653-d86a-2a2229525b63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2023-10-28 01:49:35.242300: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-28 01:49:35.242363: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-28 01:49:35.242406: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5n-cls.pt, data=Banco-Imagem-1, epochs=128, batch_size=16, imgsz=320, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=weights/yolov5n-cls.pt, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=320, width=320, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n-cls.pt to yolov5n-cls.pt...\n",
            "100% 4.87M/4.87M [00:00<00:00, 48.4MB/s]\n",
            "\n",
            "Model summary: 149 layers, 1218405 parameters, 1218405 gradients, 3.0 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 32 weight(decay=0.0), 33 weight(decay=5e-05), 33 bias\n",
            "Image sizes 320 train, 320 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-cls/exp\u001b[0m\n",
            "Starting yolov5n-cls.pt training on Banco-Imagem-1 dataset with 5 classes for 128 epochs...\n",
            "\n",
            "     Epoch   GPU_mem  train_loss   test_loss    top1_acc    top5_acc\n",
            "     1/128    0.508G        1.55        1.51       0.194           1: 100% 16/16 [00:06<00:00,  2.59it/s]\n",
            "     2/128    0.508G        1.39        1.86       0.222           1: 100% 16/16 [00:02<00:00,  6.81it/s]\n",
            "     3/128    0.508G         1.4        2.07       0.194           1: 100% 16/16 [00:02<00:00,  7.04it/s]\n",
            "     4/128    0.508G        1.35        1.75       0.222           1: 100% 16/16 [00:02<00:00,  6.38it/s]\n",
            "     5/128    0.508G        1.34        2.17       0.222           1: 100% 16/16 [00:02<00:00,  5.51it/s]\n",
            "     6/128    0.508G        1.26        1.76        0.25           1: 100% 16/16 [00:04<00:00,  3.51it/s]\n",
            "     7/128    0.508G        1.32         1.3       0.306           1: 100% 16/16 [00:02<00:00,  6.76it/s]\n",
            "     8/128    0.508G        1.27        1.57       0.333           1: 100% 16/16 [00:02<00:00,  6.99it/s]\n",
            "     9/128    0.508G        1.38         1.5       0.306           1: 100% 16/16 [00:02<00:00,  6.51it/s]\n",
            "    10/128    0.508G         1.3        1.39       0.278           1: 100% 16/16 [00:02<00:00,  5.73it/s]\n",
            "    11/128    0.508G         1.3        1.55       0.361           1: 100% 16/16 [00:03<00:00,  4.95it/s]\n",
            "    12/128    0.508G        1.28        1.45       0.306           1: 100% 16/16 [00:02<00:00,  6.98it/s]\n",
            "    13/128    0.508G        1.28        1.33       0.528           1: 100% 16/16 [00:02<00:00,  6.34it/s]\n",
            "    14/128    0.508G        1.24        1.19       0.417           1: 100% 16/16 [00:02<00:00,  6.90it/s]\n",
            "    15/128    0.508G        1.27        1.81       0.222           1: 100% 16/16 [00:03<00:00,  4.79it/s]\n",
            "    16/128    0.508G        1.25        1.52       0.361           1: 100% 16/16 [00:02<00:00,  6.45it/s]\n",
            "    17/128    0.508G        1.28         1.2       0.361           1: 100% 16/16 [00:02<00:00,  6.15it/s]\n",
            "    18/128    0.508G        1.25        1.33       0.528           1: 100% 16/16 [00:02<00:00,  6.79it/s]\n",
            "    19/128    0.508G        1.18        1.17         0.5           1: 100% 16/16 [00:02<00:00,  6.67it/s]\n",
            "    20/128    0.508G        1.23        1.33       0.306           1: 100% 16/16 [00:04<00:00,  3.52it/s]\n",
            "    21/128    0.508G        1.21        1.39       0.417           1: 100% 16/16 [00:02<00:00,  6.89it/s]\n",
            "    22/128    0.508G        1.18        1.36       0.528           1: 100% 16/16 [00:02<00:00,  6.43it/s]\n",
            "    23/128    0.508G        1.14        1.38         0.5           1: 100% 16/16 [00:02<00:00,  6.70it/s]\n",
            "    24/128    0.508G        1.17         1.3       0.556           1: 100% 16/16 [00:03<00:00,  4.59it/s]\n",
            "    25/128    0.508G         1.2        1.13       0.583           1: 100% 16/16 [00:02<00:00,  6.26it/s]\n",
            "    26/128    0.508G        1.11        1.12       0.528           1: 100% 16/16 [00:02<00:00,  6.69it/s]\n",
            "    27/128    0.508G        1.12        1.06       0.583           1: 100% 16/16 [00:02<00:00,  6.37it/s]\n",
            "    28/128    0.508G        1.12        1.45       0.417           1: 100% 16/16 [00:02<00:00,  6.95it/s]\n",
            "    29/128    0.508G        1.19        1.11         0.5           1: 100% 16/16 [00:03<00:00,  4.33it/s]\n",
            "    30/128    0.508G        1.14         1.2       0.583           1: 100% 16/16 [00:02<00:00,  6.86it/s]\n",
            "    31/128    0.508G         1.1        1.34         0.5           1: 100% 16/16 [00:02<00:00,  5.83it/s]\n",
            "    32/128    0.508G        1.17        2.32       0.278           1: 100% 16/16 [00:02<00:00,  6.40it/s]\n",
            "    33/128    0.508G        1.11        1.02       0.667           1: 100% 16/16 [00:02<00:00,  5.47it/s]\n",
            "    34/128    0.508G        1.16        1.37         0.5           1: 100% 16/16 [00:03<00:00,  5.17it/s]\n",
            "    35/128    0.508G         1.1        1.12       0.472           1: 100% 16/16 [00:02<00:00,  6.79it/s]\n",
            "    36/128    0.508G        1.08         1.2       0.556           1: 100% 16/16 [00:03<00:00,  4.22it/s]\n",
            "    37/128    0.508G        1.11        1.08       0.556           1: 100% 16/16 [00:02<00:00,  6.21it/s]\n",
            "    38/128    0.508G        1.13        1.26       0.528           1: 100% 16/16 [00:03<00:00,  4.65it/s]\n",
            "    39/128    0.508G        1.12        1.11       0.667           1: 100% 16/16 [00:02<00:00,  6.73it/s]\n",
            "    40/128    0.508G        1.11        1.19       0.639           1: 100% 16/16 [00:02<00:00,  6.53it/s]\n",
            "    41/128    0.508G        1.07       0.947       0.556           1: 100% 16/16 [00:02<00:00,  6.87it/s]\n",
            "    42/128    0.508G        1.07        1.18       0.611           1: 100% 16/16 [00:03<00:00,  5.17it/s]\n",
            "    43/128    0.508G        1.14        1.44       0.528           1: 100% 16/16 [00:02<00:00,  5.41it/s]\n",
            "    44/128    0.508G        1.05        1.01       0.667           1: 100% 16/16 [00:02<00:00,  6.64it/s]\n",
            "    45/128    0.508G        1.08        1.14       0.639           1: 100% 16/16 [00:02<00:00,  6.77it/s]\n",
            "    46/128    0.508G        1.07        1.33       0.528           1: 100% 16/16 [00:02<00:00,  6.31it/s]\n",
            "    47/128    0.508G        1.03           1       0.639           1: 100% 16/16 [00:03<00:00,  4.78it/s]\n",
            "    48/128    0.508G        1.04        1.71       0.611           1: 100% 16/16 [00:02<00:00,  5.78it/s]\n",
            "    49/128    0.508G        1.04        1.64       0.528           1: 100% 16/16 [00:02<00:00,  6.66it/s]\n",
            "    50/128    0.508G        1.02           1        0.75           1: 100% 16/16 [00:02<00:00,  6.63it/s]\n",
            "    51/128    0.508G        1.02        1.11       0.667           1: 100% 16/16 [00:02<00:00,  6.63it/s]\n",
            "    52/128    0.508G        1.06        1.59       0.611           1: 100% 16/16 [00:03<00:00,  4.26it/s]\n",
            "    53/128    0.508G       0.973        1.07       0.667           1: 100% 16/16 [00:02<00:00,  6.46it/s]\n",
            "    54/128    0.508G       0.925        1.34       0.556           1: 100% 16/16 [00:02<00:00,  6.46it/s]\n",
            "    55/128    0.508G         1.1       0.927       0.667           1: 100% 16/16 [00:03<00:00,  4.46it/s]\n",
            "    56/128    0.508G           1        1.97       0.583           1: 100% 16/16 [00:05<00:00,  3.06it/s]\n",
            "    57/128    0.508G       0.993        1.34       0.611           1: 100% 16/16 [00:02<00:00,  6.75it/s]\n",
            "    58/128    0.508G       0.954        1.17       0.639           1: 100% 16/16 [00:02<00:00,  6.50it/s]\n",
            "    59/128    0.508G        1.03        1.54         0.5           1: 100% 16/16 [00:02<00:00,  6.59it/s]\n",
            "    60/128    0.508G        1.01        1.12       0.611           1: 100% 16/16 [00:03<00:00,  5.32it/s]\n",
            "    61/128    0.508G           1        1.13       0.583           1: 100% 16/16 [00:03<00:00,  5.28it/s]\n",
            "    62/128    0.508G       0.943       0.986       0.639           1: 100% 16/16 [00:02<00:00,  6.75it/s]\n",
            "    63/128    0.508G       0.909        1.12       0.639           1: 100% 16/16 [00:02<00:00,  6.97it/s]\n",
            "    64/128    0.508G       0.888       0.867        0.75           1: 100% 16/16 [00:02<00:00,  6.32it/s]\n",
            "    65/128    0.508G       0.958       0.975       0.667           1: 100% 16/16 [00:03<00:00,  4.41it/s]\n",
            "    66/128    0.508G       0.939       0.947       0.639           1: 100% 16/16 [00:02<00:00,  6.54it/s]\n",
            "    67/128    0.508G        1.02        1.11       0.694           1: 100% 16/16 [00:03<00:00,  5.04it/s]\n",
            "    68/128    0.508G       0.998       0.971       0.667           1: 100% 16/16 [00:02<00:00,  5.55it/s]\n",
            "    69/128    0.508G       0.968        0.98       0.694           1: 100% 16/16 [00:03<00:00,  4.52it/s]\n",
            "    70/128    0.508G       0.965        1.11       0.722           1: 100% 16/16 [00:02<00:00,  6.55it/s]\n",
            "    71/128    0.508G       0.965        1.47       0.583           1: 100% 16/16 [00:02<00:00,  6.84it/s]\n",
            "    72/128    0.508G       0.953         1.2       0.611           1: 100% 16/16 [00:02<00:00,  6.54it/s]\n",
            "    73/128    0.508G       0.863       0.772       0.722           1: 100% 16/16 [00:02<00:00,  6.90it/s]\n",
            "    74/128    0.508G       0.946       0.884       0.667           1: 100% 16/16 [00:03<00:00,  4.25it/s]\n",
            "    75/128    0.508G       0.911       0.942       0.694           1: 100% 16/16 [00:02<00:00,  6.78it/s]\n",
            "    76/128    0.508G       0.964        1.16       0.694           1: 100% 16/16 [00:02<00:00,  6.80it/s]\n",
            "    77/128    0.508G       0.917         1.2       0.694           1: 100% 16/16 [00:02<00:00,  6.44it/s]\n",
            "    78/128    0.508G       0.941       0.955       0.639           1: 100% 16/16 [00:02<00:00,  6.22it/s]\n",
            "    79/128    0.508G       0.885        1.02       0.722           1: 100% 16/16 [00:03<00:00,  4.58it/s]\n",
            "    80/128    0.508G       0.864       0.802       0.694           1: 100% 16/16 [00:02<00:00,  6.33it/s]\n",
            "    81/128    0.508G       0.908        1.11       0.833           1: 100% 16/16 [00:02<00:00,  6.52it/s]\n",
            "    82/128    0.508G       0.915       0.843       0.778           1: 100% 16/16 [00:02<00:00,  6.82it/s]\n",
            "    83/128    0.508G       0.899        1.14       0.722           1: 100% 16/16 [00:03<00:00,  4.96it/s]\n",
            "    84/128    0.508G       0.826        0.81        0.75           1: 100% 16/16 [00:02<00:00,  5.77it/s]\n",
            "    85/128    0.508G       0.831       0.883       0.694           1: 100% 16/16 [00:02<00:00,  6.61it/s]\n",
            "    86/128    0.508G       0.804        0.95       0.694           1: 100% 16/16 [00:02<00:00,  6.42it/s]\n",
            "    87/128    0.508G       0.805       0.916       0.694           1: 100% 16/16 [00:02<00:00,  6.60it/s]\n",
            "    88/128    0.508G       0.824       0.936       0.667           1: 100% 16/16 [00:03<00:00,  4.40it/s]\n",
            "    89/128    0.508G       0.854       0.854       0.639           1: 100% 16/16 [00:02<00:00,  6.48it/s]\n",
            "    90/128    0.508G        0.79        1.14       0.694           1: 100% 16/16 [00:02<00:00,  6.72it/s]\n",
            "    91/128    0.508G        0.83       0.848        0.75           1: 100% 16/16 [00:02<00:00,  6.59it/s]\n",
            "    92/128    0.508G       0.805        1.32       0.639           1: 100% 16/16 [00:02<00:00,  6.47it/s]\n",
            "    93/128    0.508G       0.813        1.22        0.75           1: 100% 16/16 [00:03<00:00,  4.23it/s]\n",
            "    94/128    0.508G       0.796        0.91       0.722           1: 100% 16/16 [00:02<00:00,  6.68it/s]\n",
            "    95/128    0.508G       0.823       0.778        0.75           1: 100% 16/16 [00:02<00:00,  6.70it/s]\n",
            "    96/128    0.508G       0.827       0.898       0.806           1: 100% 16/16 [00:02<00:00,  6.50it/s]\n",
            "    97/128    0.508G       0.777       0.833       0.778           1: 100% 16/16 [00:02<00:00,  5.78it/s]\n",
            "    98/128    0.508G        0.79       0.735       0.806           1: 100% 16/16 [00:03<00:00,  4.78it/s]\n",
            "    99/128    0.508G       0.824       0.797       0.778           1: 100% 16/16 [00:02<00:00,  6.19it/s]\n",
            "   100/128    0.508G       0.802       0.893       0.806           1: 100% 16/16 [00:02<00:00,  5.94it/s]\n",
            "   101/128    0.508G       0.778        1.11       0.778           1: 100% 16/16 [00:02<00:00,  6.61it/s]\n",
            "   102/128    0.508G       0.795        1.15       0.722           1: 100% 16/16 [00:03<00:00,  4.30it/s]\n",
            "   103/128    0.508G       0.777        1.54       0.667           1: 100% 16/16 [00:02<00:00,  6.39it/s]\n",
            "   104/128    0.508G       0.764       0.916       0.722           1: 100% 16/16 [00:02<00:00,  6.66it/s]\n",
            "   105/128    0.508G       0.737        1.04       0.778           1: 100% 16/16 [00:02<00:00,  6.57it/s]\n",
            "   106/128    0.508G       0.689       0.792        0.75           1: 100% 16/16 [00:02<00:00,  6.55it/s]\n",
            "   107/128    0.508G       0.769       0.945        0.75           1: 100% 16/16 [00:03<00:00,  4.40it/s]\n",
            "   108/128    0.508G        0.78        1.21        0.75           1: 100% 16/16 [00:02<00:00,  6.61it/s]\n",
            "   109/128    0.508G       0.768       0.958        0.75           1: 100% 16/16 [00:02<00:00,  6.37it/s]\n",
            "   110/128    0.508G       0.802       0.953        0.75           1: 100% 16/16 [00:02<00:00,  6.41it/s]\n",
            "   111/128    0.508G       0.765        0.71        0.75           1: 100% 16/16 [00:02<00:00,  5.42it/s]\n",
            "   112/128    0.508G       0.709        1.07       0.722           1: 100% 16/16 [00:03<00:00,  5.15it/s]\n",
            "   113/128    0.508G       0.683         1.1       0.694           1: 100% 16/16 [00:02<00:00,  6.57it/s]\n",
            "   114/128    0.508G       0.685       0.892       0.778           1: 100% 16/16 [00:02<00:00,  6.41it/s]\n",
            "   115/128    0.508G       0.678        0.78       0.722           1: 100% 16/16 [00:02<00:00,  6.25it/s]\n",
            "   116/128    0.508G       0.714        1.19       0.722           1: 100% 16/16 [00:03<00:00,  4.29it/s]\n",
            "   117/128    0.508G       0.718       0.777       0.694           1: 100% 16/16 [00:02<00:00,  6.04it/s]\n",
            "   118/128    0.508G       0.744       0.855       0.778           1: 100% 16/16 [00:02<00:00,  6.72it/s]\n",
            "   119/128    0.508G       0.732       0.708        0.75           1: 100% 16/16 [00:02<00:00,  6.66it/s]\n",
            "   120/128    0.508G         0.7        0.88       0.778           1: 100% 16/16 [00:02<00:00,  5.85it/s]\n",
            "   121/128    0.508G       0.687       0.852       0.778           1: 100% 16/16 [00:03<00:00,  4.65it/s]\n",
            "   122/128    0.508G       0.671        1.01       0.778           1: 100% 16/16 [00:02<00:00,  6.46it/s]\n",
            "   123/128    0.508G       0.695       0.708        0.75           1: 100% 16/16 [00:02<00:00,  6.40it/s]\n",
            "   124/128    0.508G       0.685       0.725       0.778           1: 100% 16/16 [00:02<00:00,  6.69it/s]\n",
            "   125/128    0.508G       0.681       0.991        0.75           1: 100% 16/16 [00:03<00:00,  4.79it/s]\n",
            "   126/128    0.508G       0.674        0.72        0.75           1: 100% 16/16 [00:03<00:00,  4.96it/s]\n",
            "   127/128    0.508G       0.674       0.733        0.75           1: 100% 16/16 [00:02<00:00,  6.52it/s]\n",
            "   128/128    0.508G       0.687       0.682        0.75           1: 100% 16/16 [00:02<00:00,  6.48it/s]\n",
            "\n",
            "Training complete (0.105 hours)\n",
            "Results saved to \u001b[1mruns/train-cls/exp\u001b[0m\n",
            "Predict:         python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source im.jpg\n",
            "Validate:        python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data Banco-Imagem-1\n",
            "Export:          python export.py --weights runs/train-cls/exp/weights/best.pt --include onnx\n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp/weights/best.pt')\n",
            "Visualize:       https://netron.app\n",
            "\n",
            "CPU times: user 4.67 s, sys: 452 ms, total: 5.12 s\n",
            "Wall time: 6min 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validando o modelo personalizado"
      ],
      "metadata": {
        "id": "AmVHcHryhk0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data $DATASET_NAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B85YTC0hUzAf",
        "outputId": "69a129a7-70c5-4907-e151-234cd39ab399"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=Banco-Imagem-1, weights=['runs/train-cls/exp/weights/best.pt'], batch_size=128, imgsz=224, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 1214869 parameters, 0 gradients, 2.9 GFLOPs\n",
            "testing: 100% 1/1 [00:00<00:00,  1.05it/s]\n",
            "                   Class      Images    top1_acc    top5_acc\n",
            "                     all          36       0.639           1\n",
            "                  avioes           7       0.571           1\n",
            "                  barcos           6       0.667           1\n",
            "                  carros          11       0.545           1\n",
            "            helicopteros           8       0.875           1\n",
            "                   motos           4         0.5           1\n",
            "Speed: 0.1ms pre-process, 14.8ms inference, 0.6ms post-process per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/val-cls/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inferindo com o modelo personalizado"
      ],
      "metadata": {
        "id": "UxQu_RaIhyN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #'1'=avioes, '4'=carros, '2'=motos, '3'=barcos, '0'=helicopteros"
      ],
      "metadata": {
        "id": "UbvSguF0xmXd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pega a localizaÃ§Ã£o de uma imagem do conjunto de testes ou validaÃ§Ãµes\n",
        "if os.path.exists(os.path.join(dataset.location, \"test\")):\n",
        "  split_path = os.path.join(dataset.location, \"test\")\n",
        "else:\n",
        "  os.path.join(dataset.location, \"valid\")\n",
        "example_class = os.listdir(split_path)[4]\n",
        "example_image_name = os.listdir(os.path.join(split_path, example_class))[4]\n",
        "example_image_path = os.path.join(split_path, example_class, example_image_name)\n",
        "os.environ[\"TEST_IMAGE_PATH\"] = example_image_path\n",
        "\n",
        "print(f\"Inferindo sobre um exemplo da classe '{example_class}'\")\n",
        "\n",
        "#Infer\n",
        "!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source $TEST_IMAGE_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUuGVe4UY1ym",
        "outputId": "4d66f06a-751b-4626-84a7-72de40234e4f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferindo sobre um exemplo da classe 'carros'\n",
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['runs/train-cls/exp/weights/best.pt'], source=/content/yolov5/Banco-Imagem-1/test/carros/00012_jpg.rf.9f0d32646e83139878c5788b040038f7.jpg, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 1214869 parameters, 0 gradients, 2.9 GFLOPs\n",
            "image 1/1 /content/yolov5/Banco-Imagem-1/test/carros/00012_jpg.rf.9f0d32646e83139878c5788b040038f7.jpg: 224x224 carros 0.91, avioes 0.08, motos 0.01, helicopteros 0.00, barcos 0.00, 2.7ms\n",
            "Speed: 0.3ms pre-process, 2.7ms inference, 5.1ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp14\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inferindo vÃ¡rios exemplos de imagens do imgur"
      ],
      "metadata": {
        "id": "_w8Y87JKda5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aviao\n",
        "import requests\n",
        "image_url = \"https://i.imgur.com/bqs2TxC.jpg\"\n",
        "response = requests.get(image_url)\n",
        "response.raise_for_status()\n",
        "with open('aviao.jpg', 'wb') as handler:\n",
        "    handler.write(response.content)"
      ],
      "metadata": {
        "id": "oMZuEkaohMmK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights ./weights/yolov5n-cls.pt  --source aviao.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw0kxnGIivXh",
        "outputId": "3efc0f1e-6d15-4993-c12d-05ff4c82c87f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['./weights/yolov5n-cls.pt'], source=aviao.jpg, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 2489464 parameters, 0 gradients, 3.9 GFLOPs\n",
            "image 1/1 /content/yolov5/aviao.jpg: 224x224 airliner 0.79, military aircraft 0.11, wing 0.03, stretcher 0.01, parachute 0.01, 2.8ms\n",
            "Speed: 0.3ms pre-process, 2.8ms inference, 5.5ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp22\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helicoptero\n",
        "import requests\n",
        "image_url = \"https://i.imgur.com/rvFF7jA.jpg\"\n",
        "response = requests.get(image_url)\n",
        "response.raise_for_status()\n",
        "with open('helicoptero.jpg', 'wb') as handler:\n",
        "    handler.write(response.content)"
      ],
      "metadata": {
        "id": "HE_rp2iRsPuF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights ./weights/yolov5x-cls.pt --source helicoptero.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R07xssksRmen",
        "outputId": "683775e4-caf5-41ff-eedc-685534b9dd11"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['./weights/yolov5n-cls.pt'], source=helicoptero.jpg, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 2489464 parameters, 0 gradients, 3.9 GFLOPs\n",
            "image 1/1 /content/yolov5/helicoptero.jpg: 224x224 stretcher 0.13, lifeboat 0.06, military aircraft 0.06, ski 0.04, container ship 0.04, 2.9ms\n",
            "Speed: 0.3ms pre-process, 2.9ms inference, 5.3ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp27\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Moto\n",
        "import requests\n",
        "image_url = \"https://i.imgur.com/ASwjAT5.jpg\"\n",
        "response = requests.get(image_url)\n",
        "response.raise_for_status()\n",
        "with open('moto.jpg', 'wb') as handler:\n",
        "    handler.write(response.content)"
      ],
      "metadata": {
        "id": "f78Gam04sRa4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights ./weights/yolov5m-cls.pt --source moto.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU3uq4HCRmWP",
        "outputId": "49fbd5d0-1804-4ced-d4e6-39eafbe1684f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['./weights/yolov5m-cls.pt'], source=moto.jpg, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 166 layers, 12947192 parameters, 0 gradients, 31.7 GFLOPs\n",
            "image 1/1 /content/yolov5/moto.jpg: 224x224 moped 0.64, scooter 0.17, disc brake 0.06, crash helmet 0.05, snowmobile 0.01, 5.2ms\n",
            "Speed: 0.3ms pre-process, 5.2ms inference, 5.9ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp29\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Barco\n",
        "import requests\n",
        "image_url = \"https://i.imgur.com/tUbcIGU.jpg\"\n",
        "response = requests.get(image_url)\n",
        "response.raise_for_status()\n",
        "with open('barco.jpg', 'wb') as handler:\n",
        "    handler.write(response.content)"
      ],
      "metadata": {
        "id": "XHK-A93EsSji"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights ./weights/yolov5l-cls.pt --source barco.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPOXkdlORmN3",
        "outputId": "2eaf921a-6aa5-4cba-f67e-969b63608479"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['./weights/yolov5l-cls.pt'], source=barco.jpg, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 215 layers, 26535976 parameters, 0 gradients, 69.3 GFLOPs\n",
            "image 1/1 /content/yolov5/barco.jpg: 224x224 lakeshore 0.25, seashore 0.14, shipwreck 0.12, motorboat 0.09, lifeboat 0.08, 8.4ms\n",
            "Speed: 0.3ms pre-process, 8.4ms inference, 5.7ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp25\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#carro\n",
        "import requests\n",
        "image_url = \"https://i.imgur.com/GB9Tihf.jpg\"\n",
        "response = requests.get(image_url)\n",
        "response.raise_for_status()\n",
        "with open('carro.jpg', 'wb') as handler:\n",
        "    handler.write(response.content)"
      ],
      "metadata": {
        "id": "zKzqEkIdsTjU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights ./weights/yolov5x-cls.pt --source carro.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDUWfxfbRmCS",
        "outputId": "a6c0d6d9-68c8-4351-b38e-d683fb748cd7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['./weights/yolov5x-cls.pt'], source=carro.jpg, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 264 layers, 48072600 parameters, 0 gradients, 129.9 GFLOPs\n",
            "image 1/1 /content/yolov5/carro.jpg: 224x224 sports car 0.95, race car 0.02, convertible 0.01, car wheel 0.00, grille 0.00, 12.9ms\n",
            "Speed: 0.3ms pre-process, 12.9ms inference, 5.8ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp31\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}